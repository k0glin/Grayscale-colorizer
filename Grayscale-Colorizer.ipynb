{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc747f8-76d8-4143-9573-28ae9373956f",
   "metadata": {},
   "source": [
    "# Lab 2: Grayscale Colorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec265b88-8cbb-42ac-8ed0-deeb3a32e859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/gustavokoglin/miniforge3/envs/cae-env/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/gustavokoglin/miniforge3/envs/cae-env/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # [0,1]\n",
    "    # optional: transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))  # [-1,1]\n",
    "])\n",
    "\n",
    "full_train = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_set   = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Combine train+test then re-split 80/10/10\n",
    "from torch.utils.data import ConcatDataset\n",
    "all_data = ConcatDataset([full_train, test_set])\n",
    "n = len(all_data)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_set, val_set, test_set = random_split(all_data, [n_train, n_val, n_test])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader  = DataLoader(test_set, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cbbdf1-9d2d-4e06-a7b0-3c98dda828de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mConvolutionAutoEncoder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mConvolutionAutoEncoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Auto encoder\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     10\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     12\u001b[0m         nn\u001b[38;5;241m.\u001b[39mMaxPool2d(kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     13\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     14\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     15\u001b[0m         nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     16\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     20\u001b[0m     nn\u001b[38;5;241m.\u001b[39mUpsample(scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     21\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ConvolutionAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        #Auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, stride=1, padding=\"same\"),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size = 2, stride=2),\n",
    "                nn.Conv2d(in_channels = 8, out_channels = 12, kernel_size = 3, stride=1, padding=\"same\"),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "                nn.Conv2d(in_channels = 12, out_channels = 16, kernel_size = 3, stride=1, padding=\"same\"),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 12, kernel_size = 3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(in_channels = 12, out_channels = 3, kernel_size = 3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        out = self.decoder(h)\n",
    "        return out, h\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
